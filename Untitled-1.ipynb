{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcoes para ler grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix_to_edges(G_graphml):\n",
    "    matrix = nx.adjacency_matrix(nx.read_graphml(G_graphml)).todense()\n",
    "    edges = []\n",
    "    n = len(matrix)  # assuming matrix is square\n",
    "    for u in range(n):\n",
    "        for v in range(u, n):\n",
    "            if matrix[u][v] != 0:  # assuming 0 means no edge\n",
    "                edges.append((u, v, matrix[u][v]))\n",
    "    return edges, n, len(edges)\n",
    "\n",
    "G = 'graphs/0004_125.graphml'\n",
    "edges, n_nodes, m = adjacency_matrix_to_edges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_from_Bgraph(filename):\n",
    "    edges = []\n",
    "    with open(filename, 'r') as file:\n",
    "        # Skip the first line\n",
    "        if \"gset\" in filename:\n",
    "            n_nodes, n_edges = file.readline().split()\n",
    "            n_nodes, n_edges = int(n_nodes), int(n_edges)\n",
    "        else:\n",
    "            file.readline()\n",
    "            file.readline()\n",
    "            n_nodes = int(file.readline().split()[0])\n",
    "            n_edges = int(file.readline().split()[0])\n",
    "        for line in file:\n",
    "            # Split each line into components and convert to appropriate types\n",
    "            node1, node2, weight = line.split()\n",
    "            edges.append((int(node1)-1, int(node2)-1, float(weight)))\n",
    "    return edges, n_nodes, n_edges\n",
    "\n",
    "#path = \"\"\"graphs (gset)/G59.txt\"\"\"\n",
    "#edges_from_Bgraph(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_solution(edges, n_nodes, solutions=10000):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    best_solution = {node: 0 for node in range(n_nodes)}\n",
    "    best_cut_weight = 0\n",
    "    seen_solutions = set()\n",
    "\n",
    "    MEAN_WEIGHT = 0\n",
    "    for _ in range(solutions):\n",
    "        # Generate a random candidate solution\n",
    "        partition = {node: random.choice([0, 1]) for node in range(n_nodes)}\n",
    "        OPSEXEC += n_nodes\n",
    "        # avoid calculating the same solution multiple times\n",
    "        partition_hash = frozenset(partition.items()) # hash\n",
    "        # nao vou contabilizar o custo de calcular o hash pq não seria necessário se só testasse uma solucao\n",
    "        # e em grafos de maior dimensao, a probabilidade de ter solucoes iguais tende para 0 (2^n possiblidades)\n",
    "\n",
    "        if len(seen_solutions) == 2**(n_nodes): # max possible solutions\n",
    "            break\n",
    "        \n",
    "        if partition_hash in seen_solutions:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        seen_solutions.add(partition_hash)\n",
    "        OPSEXEC += 1\n",
    "        SOLTESTED += 1\n",
    "        new_cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "        MEAN_WEIGHT += new_cut_weight\n",
    "        OPSEXEC += len(edges)\n",
    "        if new_cut_weight > best_cut_weight:\n",
    "            best_cut_weight = new_cut_weight\n",
    "            best_solution = partition.copy()\n",
    "            OPSEXEC += 2\n",
    "\n",
    "    actual_it = _ + 1\n",
    "    S = set([node for node, part in best_solution.items() if part == 0]) #pos processamento, depende do q ser quer, n conta\n",
    "    T = set(range(n_nodes)) - S #pos processamento, depende do q ser quer, n conta\n",
    "    return S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it, MEAN_WEIGHT/actual_it\n",
    "\n",
    "S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it, MEAN_WEIGHT = random_solution(edges, n_nodes)\n",
    "S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it, MEAN_WEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_anlng(edges, n_nodes, initial_temp=1000, cooling_rate=0.995, min_temp=1e-3):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    nodes = range(n_nodes)\n",
    "    \n",
    "    partition = {node: random.choice([0, 1]) for node in nodes}\n",
    "    OPSEXEC += n_nodes\n",
    "    \n",
    "    # Initialize current cost\n",
    "    current_cut = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "    OPSEXEC += len(edges)\n",
    "    SOLTESTED += 1\n",
    "\n",
    "    temperature = initial_temp\n",
    "\n",
    "    best_partition = partition.copy()\n",
    "    best_cut = current_cut\n",
    "    while temperature > min_temp:\n",
    "\n",
    "        node = random.choice(nodes)\n",
    "        partition[node] = 1 - partition[node] \n",
    "        OPSEXEC += 2\n",
    "        \n",
    "        new_cut = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "        OPSEXEC += len(edges)\n",
    "        SOLTESTED += 1\n",
    "        \n",
    "        cost_diff = new_cut - current_cut\n",
    "        if cost_diff > 0 or random.random() < math.exp(cost_diff / temperature):\n",
    "            current_cut = new_cut\n",
    "            if new_cut > best_cut:\n",
    "                best_cut = new_cut\n",
    "                best_partition = partition.copy()\n",
    "                OPSEXEC += 5\n",
    "        else:\n",
    "            partition[node] = 1 - partition[node]\n",
    "            OPSEXEC += 3\n",
    "        \n",
    "        temperature *= cooling_rate\n",
    "        OPSEXEC += 1\n",
    "    \n",
    "    S = set([node for node, part in best_partition.items() if part == 0])\n",
    "    T = set(range(n_nodes)) - S\n",
    "    return S, T, best_cut, SOLTESTED, OPSEXEC\n",
    "\n",
    "S, T, best_cut, SOLTESTED, OPSEXEC = sim_anlng(edges, n_nodes)\n",
    "S, T, best_cut, SOLTESTED, OPSEXEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_greedy(edges, n_nodes):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    partition = {node: random.choice([0, 1]) for node in range(n_nodes)}\n",
    "    cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "    SOLTESTED += 1\n",
    "    OPSEXEC += len(edges) + n_nodes\n",
    "\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for node in range(n_nodes):\n",
    "            # Flip the node to the other set\n",
    "            partition[node] = 1 - partition[node]  \n",
    "            new_cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "            SOLTESTED += 1\n",
    "            OPSEXEC += len(edges) + 1\n",
    "\n",
    "            # If this move improves the cut weight, keep it; otherwise, revert\n",
    "            if new_cut_weight > cut_weight:\n",
    "                cut_weight = new_cut_weight\n",
    "                improved = True  # Continue improving\n",
    "                OPSEXEC += 2\n",
    "                break\n",
    "            else:\n",
    "                partition[node] = 1 - partition[node]\n",
    "                OPSEXEC += 1\n",
    "\n",
    "    S = set([node for node, part in partition.items() if part == 0])\n",
    "    T = set(range(n_nodes)) - S\n",
    "    return S, T, cut_weight, SOLTESTED, OPSEXEC\n",
    "\n",
    "S, T, cut_weight, SOLTESTED, OPSEXEC = random_greedy(edges, n_nodes)\n",
    "S, T, cut_weight, SOLTESTED, OPSEXEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "df = pd.read_excel('results v00.xlsx', index_col=0, header=[0,1]) # do trabalho 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dateFile = str(datetime.now().strftime(\"%m%d%H%M%S\")) \n",
    "\n",
    "alg1_ops = [np.nan for _ in range(len(df))]\n",
    "alg1_time = [np.nan for _ in range(len(df))]\n",
    "alg1_sols = [np.nan for _ in range(len(df))]\n",
    "alg1_prec = [np.nan for _ in range(len(df))]\n",
    "alg1_it = [np.nan for _ in range(len(df))]\n",
    "alg1_prec_it = [np.nan for _ in range(len(df))]\n",
    "\n",
    "alg2_ops = [np.nan for _ in range(len(df))]\n",
    "alg2_time = [np.nan for _ in range(len(df))]\n",
    "alg2_sols = [np.nan for _ in range(len(df))]\n",
    "alg2_prec = [np.nan for _ in range(len(df))]\n",
    "\n",
    "alg3_ops = [np.nan for _ in range(len(df))]\n",
    "alg3_time = [np.nan for _ in range(len(df))]\n",
    "alg3_sols = [np.nan for _ in range(len(df))]\n",
    "alg3_prec = [np.nan for _ in range(len(df))]\n",
    "\n",
    "for i in range(len(df)-1, -1, -1): # range(len(df))\n",
    "    graph = df[(\"Graph\", \"name\")][i]\n",
    "    n = df[(\"Graph\", \"n\")][i]\n",
    "    m = df[(\"Graph\", \"m\")][i]\n",
    "    weight = df[(\"Graph\", \"weight\")][i]\n",
    "    print(f\"Solving {graph}: {datetime.now().strftime('%H%M')}\")\n",
    "\n",
    "    # prepare the graph\n",
    "    if \"gset\" in graph:\n",
    "        edges, n_nodes, n_edges = edges_from_Bgraph(graph)\n",
    "    elif \"graphs/\" in graph:\n",
    "        edges, n_nodes, n_edges = adjacency_matrix_to_edges(graph)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    max_solutions = 10000       #################################### <--- mudar se quiseres\n",
    "    ALG1 = f\"Random Solutions (MS: {max_solutions})\"\n",
    "    start_time = time.time()\n",
    "    S, T, best_cut_weight, SOLTESTED, OPSEXEC, ACTUAL_IT, MEAN_WEIGHT = random_solution(edges, n_nodes, solutions=max_solutions)\n",
    "    timee = time.time() - start_time\n",
    "    alg1_ops[i] = OPSEXEC\n",
    "    alg1_time[i] = timee\n",
    "    alg1_sols[i] = SOLTESTED\n",
    "    alg1_prec[i] = best_cut_weight/weight\n",
    "    alg1_it[i] = ACTUAL_IT\n",
    "    alg1_prec_it[i] = MEAN_WEIGHT/weight\n",
    "\n",
    "    \n",
    "    temperature = 1000          #################################### <--- mudar se quiseres\n",
    "    cooling_rate = 0.99         #################################### <--- mudar se quiseres\n",
    "    ALG2 = f\"Simulated Annealing (T: {temperature}, CR: {cooling_rate})\"\n",
    "    start_time = time.time()\n",
    "    S, T, best_cut, SOLTESTED, OPSEXEC = sim_anlng(edges, n_nodes, initial_temp=temperature, cooling_rate=cooling_rate)\n",
    "    timee = time.time() - start_time\n",
    "    alg2_ops[i] = OPSEXEC\n",
    "    alg2_time[i] = timee\n",
    "    alg2_sols[i] = SOLTESTED\n",
    "    alg2_prec[i] = best_cut/weight\n",
    "\n",
    "    ALG3 = \"Random Greedy\"\n",
    "    start_time = time.time()\n",
    "    S, T, cut_weight, SOLTESTED, OPSEXEC = random_greedy(edges, n_nodes)\n",
    "    timee = time.time() - start_time\n",
    "    alg3_ops[i] = OPSEXEC\n",
    "    alg3_time[i] = timee\n",
    "    alg3_sols[i] = SOLTESTED\n",
    "    alg3_prec[i] = cut_weight/weight\n",
    "\n",
    "\n",
    "    df[(ALG1, \"#ops\")] = alg1_ops\n",
    "    df[(ALG1, \"time\")] = alg1_time\n",
    "    df[(ALG1, \"#sols\")] = alg1_sols\n",
    "    df[(ALG1, \"prec.\")] = alg1_prec\n",
    "    df[(ALG1, \"it.\")] = alg1_it\n",
    "    df[(ALG1, \"prec./it.\")] = alg1_prec_it\n",
    "\n",
    "    df[(ALG2, \"#ops\")] = alg2_ops\n",
    "    df[(ALG2, \"time\")] = alg2_time\n",
    "    df[(ALG2, \"#sols\")] = alg2_sols\n",
    "    df[(ALG2, \"prec.\")] = alg2_prec\n",
    "\n",
    "    df[(ALG3, \"#ops\")] = alg3_ops\n",
    "    df[(ALG3, \"time\")] = alg3_time\n",
    "    df[(ALG3, \"#sols\")] = alg3_sols\n",
    "    df[(ALG3, \"prec.\")] = alg3_prec\n",
    "\n",
    "\n",
    "    df.to_excel(f\"results_{dateFile}.xlsx\")\n",
    "\n",
    "print(\"Done! i hope...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
