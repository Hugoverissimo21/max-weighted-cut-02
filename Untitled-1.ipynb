{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcoes para ler grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix_to_edges(G_graphml):\n",
    "    matrix = nx.adjacency_matrix(nx.read_graphml(G_graphml)).todense()\n",
    "    edges = []\n",
    "    n = len(matrix)  # assuming matrix is square\n",
    "    for u in range(n):\n",
    "        for v in range(u, n):\n",
    "            if matrix[u][v] != 0:  # assuming 0 means no edge\n",
    "                edges.append((u, v, matrix[u][v]))\n",
    "    return edges, n, len(edges)\n",
    "\n",
    "G = 'graphs/0005_500.graphml'\n",
    "edges, n_nodes, m = adjacency_matrix_to_edges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_from_Bgraph(filename):\n",
    "    edges = []\n",
    "    with open(filename, 'r') as file:\n",
    "        # Skip the first line\n",
    "        if \"gset\" in filename:\n",
    "            n_nodes, n_edges = file.readline().split()\n",
    "            n_nodes, n_edges = int(n_nodes), int(n_edges)\n",
    "        else:\n",
    "            file.readline()\n",
    "            file.readline()\n",
    "            n_nodes = int(file.readline().split()[0])\n",
    "            n_edges = int(file.readline().split()[0])\n",
    "        for line in file:\n",
    "            # Split each line into components and convert to appropriate types\n",
    "            node1, node2, weight = line.split()\n",
    "            edges.append((int(node1)-1, int(node2)-1, float(weight)))\n",
    "    return edges, n_nodes, n_edges\n",
    "\n",
    "#path = \"\"\"graphs (gset)/G59.txt\"\"\"\n",
    "#edges_from_Bgraph(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 2, 3}, {1, 4}, np.int64(62), 32, 955, 151)"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_solution(edges, n_nodes, solutions=10000):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    best_solution = None\n",
    "    best_cut_weight = 0\n",
    "    seen_solutions = set()\n",
    "\n",
    "    for _ in range(solutions):\n",
    "        # Generate a random candidate solution\n",
    "        partition = {node: random.choice([0, 1]) for node in range(n_nodes)}\n",
    "        OPSEXEC += n_nodes\n",
    "        # avoid calculating the same solution multiple times\n",
    "        partition_hash = frozenset(partition.items()) # hash\n",
    "        # nao vou contabilizar o custo de calcular o hash pq não seria necessário se só testasse uma solucao\n",
    "        # e em grafos de maior dimensao, a probabilidade de ter solucoes iguais tende para 0 (2^n possiblidades)\n",
    "\n",
    "        if len(seen_solutions) == 2**(n_nodes): # max possible solutions\n",
    "            break\n",
    "        \n",
    "        if partition_hash in seen_solutions:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        seen_solutions.add(partition_hash)\n",
    "        OPSEXEC += 1\n",
    "        SOLTESTED += 1\n",
    "        new_cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "        OPSEXEC += len(edges)\n",
    "        if new_cut_weight > best_cut_weight:\n",
    "            best_cut_weight = new_cut_weight\n",
    "            best_solution = partition.copy()\n",
    "            OPSEXEC += 2\n",
    "\n",
    "    actual_it = _ + 1\n",
    "    S = set([node for node, part in best_solution.items() if part == 0]) #pos processamento, depende do q ser quer, n conta\n",
    "    T = set(range(n_nodes)) - S #pos processamento, depende do q ser quer, n conta\n",
    "    return S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it\n",
    "\n",
    "S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it = random_solution(edges, n_nodes)\n",
    "S, T, best_cut_weight, SOLTESTED, OPSEXEC, actual_it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 2, 3}, {1, 4}, np.int64(62), 2758, 27894)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_anlng(edges, n_nodes, initial_temp=1000, cooling_rate=0.995, min_temp=1e-3):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    nodes = range(n_nodes)\n",
    "    \n",
    "    partition = {node: random.choice([0, 1]) for node in nodes}\n",
    "    OPSEXEC += n_nodes\n",
    "    \n",
    "    # Initialize current cost\n",
    "    current_cut = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "    OPSEXEC += len(edges)\n",
    "    SOLTESTED += 1\n",
    "\n",
    "    temperature = initial_temp\n",
    "\n",
    "    best_partition = partition.copy()\n",
    "    best_cut = current_cut\n",
    "    while temperature > min_temp:\n",
    "\n",
    "        node = random.choice(nodes)\n",
    "        partition[node] = 1 - partition[node] \n",
    "        OPSEXEC += 2\n",
    "        \n",
    "        new_cut = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "        OPSEXEC += len(edges)\n",
    "        SOLTESTED += 1\n",
    "        \n",
    "        cost_diff = new_cut - current_cut\n",
    "        if cost_diff > 0 or random.random() < math.exp(cost_diff / temperature):\n",
    "            current_cut = new_cut\n",
    "            if new_cut > best_cut:\n",
    "                best_cut = new_cut\n",
    "                best_partition = partition.copy()\n",
    "                OPSEXEC += 5\n",
    "        else:\n",
    "            partition[node] = 1 - partition[node]\n",
    "            OPSEXEC += 3\n",
    "        \n",
    "        temperature *= cooling_rate\n",
    "        OPSEXEC += 1\n",
    "    \n",
    "    S = set([node for node, part in best_partition.items() if part == 0])\n",
    "    T = set(range(n_nodes)) - S\n",
    "    return S, T, best_cut, SOLTESTED, OPSEXEC\n",
    "\n",
    "S, T, best_cut, SOLTESTED, OPSEXEC = sim_anlng(edges, n_nodes)\n",
    "S, T, best_cut, SOLTESTED, OPSEXEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2}, {3, 4}, np.int64(40), 6, 45)"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_greedy(edges, n_nodes):\n",
    "    SOLTESTED, OPSEXEC = 0, 0\n",
    "\n",
    "    partition = {node: random.choice([0, 1]) for node in range(n_nodes)}\n",
    "    cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "    SOLTESTED += 1\n",
    "    OPSEXEC += len(edges) + n_nodes\n",
    "\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for node in range(n_nodes):\n",
    "            # Flip the node to the other set\n",
    "            partition[node] = 1 - partition[node]  \n",
    "            new_cut_weight = sum(weight for node1, node2, weight in edges if partition[node1] != partition[node2])\n",
    "            SOLTESTED += 1\n",
    "            OPSEXEC += len(edges) + 1\n",
    "\n",
    "            # If this move improves the cut weight, keep it; otherwise, revert\n",
    "            if new_cut_weight > cut_weight:\n",
    "                cut_weight = new_cut_weight\n",
    "                improved = True  # Continue improving\n",
    "                OPSEXEC += 2\n",
    "                break\n",
    "            else:\n",
    "                partition[node] = 1 - partition[node]\n",
    "                OPSEXEC += 1\n",
    "\n",
    "    S = set([node for node, part in partition.items() if part == 0])\n",
    "    T = set(range(n_nodes)) - S\n",
    "    return S, T, cut_weight, SOLTESTED, OPSEXEC\n",
    "\n",
    "S, T, cut_weight, SOLTESTED, OPSEXEC = random_greedy(edges, n_nodes)\n",
    "S, T, cut_weight, SOLTESTED, OPSEXEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G41.txt',\n",
       " 'G55.txt',\n",
       " 'G2.txt',\n",
       " 'G3.txt',\n",
       " 'G54.txt',\n",
       " 'G40.txt',\n",
       " 'G56.txt',\n",
       " 'G42.txt',\n",
       " 'G81.txt',\n",
       " 'G1.txt',\n",
       " 'G43.txt',\n",
       " 'G57.txt',\n",
       " 'G53.txt',\n",
       " 'G47.txt',\n",
       " 'G4.txt',\n",
       " '.DS_Store',\n",
       " 'G5.txt',\n",
       " 'G46.txt',\n",
       " 'G52.txt',\n",
       " 'G44.txt',\n",
       " 'G50.txt',\n",
       " 'G7.txt',\n",
       " 'G6.txt',\n",
       " 'G51.txt',\n",
       " 'G45.txt',\n",
       " 'G22.txt',\n",
       " 'G36.txt',\n",
       " 'G37.txt',\n",
       " 'G23.txt',\n",
       " 'G35.txt',\n",
       " 'G21.txt',\n",
       " 'G20.txt',\n",
       " 'G34.txt',\n",
       " 'G30.txt',\n",
       " 'G24.txt',\n",
       " 'G18.txt',\n",
       " 'G19.txt',\n",
       " 'G25.txt',\n",
       " 'G31.txt',\n",
       " 'description.csv',\n",
       " 'G27.txt',\n",
       " 'G33.txt',\n",
       " 'G32.txt',\n",
       " 'G26.txt',\n",
       " 'G17.txt',\n",
       " 'G16.txt',\n",
       " 'G28.txt',\n",
       " 'G14.txt',\n",
       " '.gitignore',\n",
       " 'G15.txt',\n",
       " 'G29.txt',\n",
       " 'G11.txt',\n",
       " 'G39.txt',\n",
       " 'G38.txt',\n",
       " 'G10.txt',\n",
       " 'G12.txt',\n",
       " 'G13.txt',\n",
       " 'G48.txt',\n",
       " 'G60.txt',\n",
       " 'G61.txt',\n",
       " 'G49.txt',\n",
       " 'G77.txt',\n",
       " 'G63.txt',\n",
       " '0README.md',\n",
       " 'G8.txt',\n",
       " 'G9.txt',\n",
       " 'G62.txt',\n",
       " 'G72.txt',\n",
       " 'G66.txt',\n",
       " 'G67.txt',\n",
       " 'G65.txt',\n",
       " 'G59.txt',\n",
       " 'G58.txt',\n",
       " 'G70.txt',\n",
       " 'G64.txt']"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "[os.listdir('graphs (gset)') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "\n",
    "for g in graphs:\n",
    "random_solution(edges, n_nodes, solutions=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec time, precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
